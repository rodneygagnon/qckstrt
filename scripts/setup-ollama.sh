#!/bin/bash

# Setup Ollama with Falcon 7B model
# This script pulls the required model into the Ollama container

echo "üöÄ Setting up Ollama with Falcon 7B..."

# Check if Ollama container is running
if ! docker ps | grep -q qckstrt-ollama; then
    echo "‚ùå Ollama container is not running"
    echo "Please run: docker-compose up -d ollama"
    exit 1
fi

echo "üì• Pulling Falcon 7B model (this may take a few minutes)..."
docker exec qckstrt-ollama ollama pull falcon

echo "‚úÖ Falcon 7B model installed!"
echo ""
echo "You can now use Falcon 7B for LLM inference."
echo ""
echo "To verify, run:"
echo "  docker exec qckstrt-ollama ollama list"
echo ""
echo "To test the model:"
echo "  docker exec qckstrt-ollama ollama run falcon 'Hello, how are you?'"
